{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Code for Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import numpy as np\n",
    "from scipy.stats import lognorm\n",
    "import math\n",
    "from scipy.special import erf\n",
    "from scipy.stats import norm\n",
    "sns.set_style(\"white\")\n",
    "sns.set_palette(sns.color_palette(\"colorblind\"))\n",
    "\n",
    "from modules.classifiers import make_mlp\n",
    "from modules.layers import LogUniformAllBMRPruningLayer\n",
    "from modules.layers import gather_pruning_layers\n",
    "\n",
    "\n",
    "def loguniform(low=0, high=1, size=None):\n",
    "    return np.exp(np.random.uniform(low, high, size))\n",
    "\n",
    "def trunc_logu_pdf(x, a, b):\n",
    "    return 1 / (x * (b - a))\n",
    "\n",
    "def trunc_exp_pdf(x, a, b, lam):\n",
    "    return np.exp(-lam*x) / (np.exp(-lam*a) - np.exp(-lam*b))\n",
    "\n",
    "def truncated_lognormal_pdf(x, mu=0, var=1, a=-20, b=0):\n",
    "    assert (np.exp(a) <= x).all() and (np.exp(b) >= x).all()\n",
    "    \n",
    "    sig = np.sqrt(var)\n",
    "    alpha = (a - mu) / sig\n",
    "    beta = (b - mu) / sig\n",
    "    Z = norm.cdf(beta) - norm.cdf(alpha)\n",
    "    \n",
    "    return 1 / (Z*x*np.sqrt(2*np.pi*var)) * np.exp(-(np.log(x) - mu)**2 / (2*var))\n",
    "\n",
    "\n",
    "model = make_mlp(\n",
    "            in_dim=32*32*3,\n",
    "            out_dim=10,\n",
    "            n_layers=5,\n",
    "            hidden_dim=150,\n",
    "            pruning_class=LogUniformAllBMRPruningLayer,\n",
    "            enable_pruning=True\n",
    "        )\n",
    "model.load_state_dict(torch.load(f'latex/paper_items/cifar10_mlp_1000.pth', map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(30,7))\n",
    "plt.rc('axes', titlesize=40)  # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=40)  # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=40)  # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=40)  # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=40)  # legend fontsize\n",
    "plt.rcParams['text.usetex'] = True\n",
    "#sns.despine()\n",
    "a = -20\n",
    "b = 0\n",
    "x = np.linspace(np.exp(a), np.exp(b), 100)\n",
    "y = trunc_logu_pdf(x,a,b)\n",
    "mu = -20\n",
    "sigma = 10\n",
    "y2 = truncated_lognormal_pdf(x, mu, sigma**2, a, b)\n",
    "sns.lineplot(x=x, y=y, color='black', label=\"Original Prior\", linewidth=8, ax=ax[1])\n",
    "logu_color = ax[1].lines[-1].get_color()\n",
    "sns.lineplot(x=x, y=y2, color='black', linestyle='--', label=\"Reduced Prior\", linewidth=8, ax=ax[1])\n",
    "logn_color = ax[1].lines[-1].get_color()\n",
    "\n",
    "ax[1].set_ylim(0.,5.)\n",
    "#ax.fill_between(x,y, color=logu_color, alpha=0.3)\n",
    "ax[1].fill_between(x,y2, color=logn_color, alpha=0.3)\n",
    "ax[1].set_yticks([], labels=[])\n",
    "ax[1].set_xlim((0.,1.))\n",
    "\n",
    "layers = gather_pruning_layers(model)\n",
    "Enoise = np.concatenate([l.Etheta().detach().cpu().numpy() for l in layers])\n",
    "Enoise_pruned = np.concatenate([l.Etheta()[l.mask == 1].detach().cpu().numpy() for l in layers])\n",
    "\n",
    "sns.histplot(Enoise, bins=20,kde=True, color='black', ax=ax[0], line_kws={'linewidth': 8}, label='$E[\\\\theta]$')\n",
    "ax[0].set_ylim((0., 30.))\n",
    "ax[0].legend()\n",
    "ax[0].set_yticks([], labels=[])\n",
    "ax[0].set_ylabel(\"\")\n",
    "ax[0].set_xlim((0.,1.))\n",
    "ax[1].set_facecolor((0.082, 0.376, 0.510, 0.05))\n",
    "\n",
    "sns.histplot(Enoise_pruned, bins=20,kde=True, color='black', ax=ax[2], line_kws={'linewidth': 8}, label='$E[\\\\theta]$ BMRS$_{\\\\mathcal{N}}$')\n",
    "ax[2].set_ylim((0., 30.))\n",
    "ax[2].legend()\n",
    "ax[2].set_yticks([], labels=[])\n",
    "ax[2].set_ylabel(\"\")\n",
    "ax[2].set_xlim((0.,1.))\n",
    "\n",
    "for axc in ax:\n",
    "    axc.set_xticks([np.exp(-20), 0.5, 1], labels=[\"$e^-20$\", \"0.5\", \"1\"])\n",
    "    for axis in ['bottom','left', 'top', 'right']:\n",
    "        axc.spines[axis].set_linewidth(3)\n",
    "    \n",
    "plt.tight_layout(w_pad=20.0)\n",
    "plt.savefig('./latex/figures/figure1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
